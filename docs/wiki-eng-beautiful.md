# ğŸ¤– FEDOT.LLM Documentation

<div align="center">

*Intelligent AI Assistant for Automated Machine Learning*

[![English](https://img.shields.io/badge/Documentation-English-34C759?style=for-the-badge&logo=github)](https://github.com/aimclub/FEDOT.LLM/blob/main/docs/wiki-eng-beautiful.md)  
[![Ğ ÑƒÑÑĞºĞ¸Ğ¹](https://img.shields.io/badge/Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ-Ğ ÑƒÑÑĞºĞ¸Ğ¹-4A90E2?style=for-the-badge&logo=github)](https://github.com/aimclub/FEDOT.LLM/blob/main/docs/wiki-ru-beautiful.md)

[![Python](https://img.shields.io/badge/Python-3.10+-blue?style=flat-square&logo=python)](https://python.org)
[![LLM](https://img.shields.io/badge/LLM-Powered-ff6b6b?style=flat-square&logo=openai)](https://openai.com)
[![AutoML](https://img.shields.io/badge/AutoML-FEDOT-success?style=flat-square&logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTEyIDJMMTMuMDkgOC4yNkwyMCA5TDEzLjA5IDE1Ljc0TDEyIDIyTDEwLjkxIDE1Ljc0TDQgOUwxMC45MSA4LjI2TDEyIDJaIiBmaWxsPSJ3aGl0ZSIvPgo8L3N2Zz4K)](https://github.com/aimclub/FEDOT)
[![Streamlit](https://img.shields.io/badge/Interface-Streamlit-ff4b4b?style=flat-square&logo=streamlit)](https://streamlit.io)

[![GitHub stars](https://img.shields.io/github/stars/aimclub/FEDOT.LLM?style=social)](https://github.com/aimclub/FEDOT.LLM)

![FEDOT.LLM Banner](/docs/fedot-llm.png)

</div>

---

## ğŸ“‹ Table of Contents

<details>
<summary><b>ğŸ¯ Getting Started</b></summary>

- [ğŸ” Project Overview](#-project-overview)
- [âš™ï¸ Installation and Setup](#%EF%B8%8F-installation-and-setup)
  - [ğŸ“¦ Basic Installation](#-basic-installation)
    - [ğŸš€ Method 1: Using uv (Recommended)](#-method-1-using-uv-recommended)
    - [ğŸ Method 2: Using conda](#-method-2-using-conda)
  - [ğŸ”§ Environment Configuration](#-environment-configuration)

</details>

<details>
<summary><b>ğŸ—ï¸ Architecture & Components</b></summary>

- [ğŸ›ï¸ Overall System Architecture](#%EF%B8%8F-overall-system-architecture)
  - [ğŸ”„ Main Application Flow](#-main-application-flow)
  - [ğŸ¤– Agent System](#-agent-system)
    - [ğŸ‘¨â€ğŸ’¼ Supervisor Agent](#-supervisor-agent)
    - [ğŸ”¬ Researcher Agent](#-researcher-agent)
    - [ğŸ’¾ Data Management and Memory](#-data-management-and-memory)
    - [ğŸ§  AutoML Agent](#-automl-agent)

</details>

<details>
<summary><b>ğŸ“Š Data & Interface</b></summary>

- [ğŸ“ˆ Data Loading and Representation](#-data-loading-and-representation)
- [ğŸŒ Streamlit Web Interface](#-streamlit-web-interface)
- [ğŸ¨ Template System](#-template-system)

</details>

---

## ğŸ” Project Overview

<div align="center">

> **ğŸš€ Revolutionizing Machine Learning with Intelligent AI Agents**

</div>

**FEDOT.LLM** is a cutting-edge project that harnesses the power of **Large Language Models (LLMs)** to transform automated machine learning (AutoML) tasks and research assistance. At its core lies an intelligent system that understands, adapts, and delivers sophisticated machine learning solutions through natural language interaction.

### âœ¨ Key Features

<table>
<tr>
<td width="50%">

**ğŸ¤– Intelligent Agent System**
- **Supervisor Agent**: Central coordination and task routing
- **Researcher Agent**: Documentation understanding and grounded responses
- **AutoML Agent**: Automated ML pipeline generation and optimization

</td>
<td width="50%">

**ğŸ”§ Advanced Capabilities**
- **Natural Language Processing**: Understand complex ML requirements
- **Code Generation**: Automatic Python code creation for ML pipelines
- **Interactive Web Interface**: Streamlit-based conversational UI

</td>
</tr>
<tr>
<td width="50%">

**ğŸ“Š Data Management**
- **Multi-format Support**: CSV, Parquet, Excel, ARFF
- **Vector Database**: ChromaDB for efficient document retrieval
- **Memory Management**: Context-aware information storage

</td>
<td width="50%">

**ğŸ¯ Use Cases**
- **AutoML Solutions**: End-to-end ML pipeline development
- **Research Assistance**: Documentation-based question answering
- **Educational Support**: Learning ML concepts through interaction

</td>
</tr>
</table>

### ğŸ¯ Core Philosophy

The system operates on a **modular, agent-based architecture** that enables:

- ğŸ”„ **Dynamic Adaptation**: Automatic adjustment to problem requirements
- ğŸ” **Iterative Refinement**: Continuous improvement of solutions
- ğŸ—ï¸ **Scalable Design**: Easy integration of new capabilities
- ğŸ›¡ï¸ **Isolated Execution**: Safe code execution in sandboxed environments

### ğŸŒŸ What Makes FEDOT.LLM Special?

| Feature | Description | Benefit |
|---------|-------------|---------|
| ğŸ§  **LLM-Powered Intelligence** | Leverages state-of-the-art language models | Natural, intuitive interaction |
| ğŸ”— **Agent Orchestration** | Specialized agents for different tasks | Efficient, focused problem-solving |
| ğŸ“ **Grounded Responses** | Documentation-based answer generation | Accurate, reliable information |
| âš¡ **Automated Workflows** | End-to-end ML pipeline automation | Rapid prototyping and deployment |
| ğŸ¨ **Template System** | Flexible code and prompt generation | Consistent, maintainable outputs |

---

## âš™ï¸ Installation and Setup

<div align="center">

> **ğŸ“¦ Get up and running in minutes!**

</div>

### ğŸ“¦ Basic Installation

We offer two installation methods to suit your preferences:

<div align="center">

| Method | Difficulty | Speed | Recommended |
|--------|------------|-------|-------------|
| ğŸš€ **uv** | Easy | âš¡ Ultra Fast | âœ… **Yes** |
| ğŸ **conda** | Easy | ğŸŒ Standard | âš ï¸ Alternative |

</div>

#### ğŸš€ Method 1: Using uv (Recommended)

<details>
<summary><b>ğŸ“‹ Step-by-step installation with uv</b></summary>

**Step 1: Install uv**
> A blazingly fast Python package installer and resolver

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

**Step 2: Clone the repository**
```bash
git clone https://github.com/aimclub/FEDOT.LLM.git
cd FEDOT.LLM
```

**Step 3: Create and activate virtual environment**
```bash
uv venv --python 3.10
source .venv/bin/activate  # On Unix/macOS
# Or on Windows:
# .venv\Scripts\activate
```

**Step 4: Install dependencies**
```bash
uv sync
```

</details>

#### ğŸ Method 2: Using conda

<details>
<summary><b>ğŸ“‹ Step-by-step installation with conda</b></summary>

**Step 1: Create conda environment**
```bash
conda create -n FedotLLM python=3.10
conda activate FedotLLM
```

**Step 2: Clone the repository**
```bash
git clone https://github.com/aimclub/FEDOT.LLM.git
cd FEDOT.LLM
```

**Step 3: Install dependencies**
```bash
pip install -e .
```

</details>

### ğŸ”§ Environment Configuration

<div align="center">

> **ğŸ” Secure your API access for optimal performance**

</div>

FEDOT.LLM requires API keys to access LLM services. Configure them through environment variables for seamless operation.

#### Option 1: Create `.env` file (Recommended)

Create a `.env` file in the project root:

```bash
# Required API Keys
FEDOTLLM_LLM_API_KEY=your_llm_api_key_here
FEDOTLLM_EMBEDDINGS_API_KEY=your_embeddings_api_key_here

# Optional: For tracing LLM calls with Langfuse
LANGFUSE_SECRET_KEY=your_langfuse_secret_key_here
LANGFUSE_PUBLIC_KEY=your_langfuse_public_key_here
```

#### Option 2: Export directly

```bash
export FEDOTLLM_LLM_API_KEY=your_llm_api_key_here
export FEDOTLLM_EMBEDDINGS_API_KEY=your_embeddings_api_key_here

# Optional: For tracing LLM calls with Langfuse
export LANGFUSE_SECRET_KEY=your_langfuse_secret_key_here
export LANGFUSE_PUBLIC_KEY=your_langfuse_public_key_here
```

<div align="center">

**ğŸ‰ Congratulations! You're ready to explore FEDOT.LLM**

</div>

---

## ğŸ›ï¸ Overall System Architecture

<div align="center">

> **ğŸ”— Intelligent Agent Orchestration for Advanced ML Solutions**

</div>

The **FEDOT.LLM** project represents a paradigm shift in automated machine learning, featuring an **intelligent, agent-based architecture** that seamlessly integrates large language models with sophisticated automation workflows.

### ğŸ¯ Architecture Principles

<div align="center">

| Principle | Description | Benefit |
|-----------|-------------|---------|
| ğŸ¤– **Agent-Based Design** | Specialized AI agents for different tasks | Focused expertise and efficient processing |
| ğŸ”„ **Modular Architecture** | Separable, interchangeable components | Easy maintenance and extensibility |
| ğŸ›¡ï¸ **Isolated Execution** | Sandboxed code execution environment | Security and reliability |
| ğŸ“Š **Vector-Based Memory** | ChromaDB for intelligent document retrieval | Context-aware responses |

</div>

### ğŸ”„ Main Application Flow

The system orchestrates complex workflows through intelligent agent coordination:

```mermaid
graph TD
    A[ğŸ‘¤ User Input] --> B[ğŸ“‹ main.py]
    B --> C{ğŸ¤µ Supervisor Agent}
    C -- "ğŸ“Š ML Task" --> D[ğŸ§  AutoML Agent]
    C -- "ğŸ“š Research Query" --> E[ğŸ”¬ Researcher Agent]
    C -- "âœ… Task Complete" --> F[ğŸ Finish]
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#fff3e0
    style D fill:#e8f5e8
    style E fill:#fce4ec
    style F fill:#f1f8e9
```

### ğŸ¤– Agent System

Our multi-agent system provides specialized intelligence for different domains:

#### ğŸ‘¨â€ğŸ’¼ Supervisor Agent

<div align="center">

**ğŸ§­ The Central Command & Control**

</div>

The **Supervisor Agent** acts as the intelligent orchestrator, analyzing conversation context and routing requests to appropriate specialists:

```mermaid
graph TD
    A[ğŸ“ Conversation History] --> B{ğŸ¤” Analyze Intent}
    B --> C[ğŸ§  AutoML Tasks]
    B --> D[ğŸ“š Research Queries]
    B --> E[âœ… Completed Tasks]
    
    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#e8f5e8
    style D fill:#fce4ec
    style E fill:#f1f8e9
```

**Key Capabilities:**
- ğŸ¯ **Intent Recognition**: Automatically determines task type
- ğŸ”€ **Smart Routing**: Directs requests to optimal agents
- ğŸ“Š **Context Management**: Maintains conversation state

#### ğŸ”¬ Researcher Agent

<div align="center">

**ğŸ“– Documentation Expert & Knowledge Navigator**

</div>

The **Researcher Agent** specializes in providing accurate, grounded responses from documentation sources:

```mermaid
graph TD
    Start([ğŸš€ START]) --> Retrieve[ğŸ“š Retrieve Documents]
    Retrieve --> Grade{ğŸ“Š Grade Relevance}
    Grade -->|âœ… Relevant| Generate[ğŸ“ Generate Response]
    Grade -->|âŒ Irrelevant| Rewrite[âœï¸ Rewrite Question]
    Rewrite --> Retrieve
    Generate --> Grounded{ğŸ” Is Grounded?}
    Grounded -->|âœ… Yes| Useful{ğŸ’¡ Is Useful?}
    Grounded -->|âŒ No| Generate
    Useful -->|âœ… Yes| Render[ğŸ¨ Render Answer]
    Useful -->|âŒ No| Rewrite
    Render --> End([ğŸ END])
    
    style Start fill:#4caf50
    style End fill:#f44336
    style Generate fill:#2196f3
    style Render fill:#ff9800
```

**Advanced Features:**
- ğŸ” **Hallucination Detection**: Ensures factual accuracy
- ğŸ“‘ **Source Citation**: Links answers to documentation
- ğŸ”„ **Iterative Refinement**: Improves response quality
- ğŸ¯ **Question Rewriting**: Optimizes retrieval effectiveness

#### ğŸ’¾ Data Management and Memory

The system employs sophisticated data management using **ChromaDB** for vector-based storage:

```mermaid
graph TD
    A[ğŸ“„ Raw Documents] --> B[ğŸ”§ Retrieve Agent]
    B --> C[âœ‚ï¸ Chunk Text]
    C --> D[ğŸ§  Generate Embeddings]
    D --> E[ğŸ’¾ ChromaDB Storage]
    E --> F[ğŸ” Vector Search]
    
    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#e8f5e8
    style D fill:#fce4ec
    style E fill:#f1f8e9
    style F fill:#e1f5fe
```

#### ğŸ§  AutoML Agent

<div align="center">

**ğŸ¯ Automated Machine Learning Pipeline Expert**

</div>

The **AutoML Agent** transforms natural language descriptions into complete machine learning solutions:

```mermaid
graph TD
    START[ğŸš€ Start] --> Reflect[ğŸ¤” Problem Reflection]
    Reflect --> Config[âš™ï¸ Generate AutoML Config]
    Config --> Skeleton[ğŸ¦´ Select Skeleton]
    Skeleton --> Code[ğŸ’» Generate Code]
    Code --> Templates[ğŸ“ Insert Templates]
    Templates --> Evaluate[ğŸ” Evaluate Main]
    Evaluate -->|ğŸ› Bug| Fix[ğŸ”§ Fix Solution]
    Evaluate -->|âœ… Success| Tests[ğŸ§ª Run Tests]
    Fix --> Templates
    Tests -->|ğŸ› Bug| Fix
    Tests -->|âœ… Success| Metrics[ğŸ“Š Extract Metrics]
    Metrics --> Report[ğŸ“‹ Generate Report]
    Report --> END[ğŸ End]
    
    style START fill:#4caf50
    style END fill:#f44336
    style Code fill:#2196f3
    style Report fill:#ff9800
```

**Workflow Capabilities:**
- ğŸ§  **Problem Understanding**: Interprets ML requirements
- ğŸ”§ **Code Generation**: Creates executable Python pipelines
- ğŸ› **Error Handling**: Automatic bug detection and fixing
- ğŸ“Š **Performance Evaluation**: Comprehensive metrics extraction
- ğŸ“‹ **Report Generation**: Detailed solution documentation

---

## ğŸ“ˆ Data Loading and Representation

<div align="center">

> **ğŸ“Š Comprehensive Support for Multiple Data Formats**

</div>

The `fedotllm.data` module provides robust data handling capabilities for various file formats:

### Supported File Formats

| Category | Extensions | Use Case |
|----------|------------|----------|
| ğŸ“„ **CSV** | `.csv` | Standard tabular data |
| ğŸ“¦ **Parquet** | `.parquet`, `.pq` | Optimized columnar storage |
| ğŸ“Š **Excel** | `.xls`, `.xlsx`, `.xlsm`, `.xlsb`, `.odf`, `.ods`, `.odt` | Spreadsheet data |
| ğŸ”¢ **ARFF** | `.arff` | Weka-compatible format |

### Data Loading Process

```mermaid
graph TD
    A[ğŸ“ Input Path] --> B{ğŸ“‚ Directory?}
    B -->|Yes| C[ğŸ” Scan Files]
    B -->|No| J[ğŸš« Skip]
    C --> D{ğŸ“„ Valid Extension?}
    D -->|Yes| E[ğŸ“š Load DataFrame]
    D -->|No| C
    E --> F[ğŸ“‹ Create Split Object]
    F --> G[â• Add to Dataset]
    G --> C
    C --> H{âœ… All Processed?}
    H -->|Yes| I[ğŸ¯ Return Dataset]
    H -->|No| C
    I --> END[ğŸ Complete]
    J --> END
    
    style A fill:#e3f2fd
    style I fill:#4caf50
    style END fill:#f44336
```

---

## ğŸŒ Streamlit Web Interface

<div align="center">

> **ğŸ’¬ Conversational AI Interface for ML Solutions**

</div>

The FEDOT.LLM web interface provides an intuitive, chat-based experience for interacting with AI agents and managing ML workflows.

### Architecture Overview

```mermaid
graph TD
    User[ğŸ‘¤ User] -->|Input Prompt| UI[ğŸŒ Streamlit UI]
    UI -->|Call ask| Backend[âš™ï¸ Backend App]
    Backend -->|Stream Response| UI
    UI -->|Render Content| User
    UI -->|Download Artifacts| FS[ğŸ’¾ Local Filesystem]
    FS -->|Upload Data| UI
    
    style User fill:#e1f5fe
    style UI fill:#fff3e0
    style Backend fill:#e8f5e8
    style FS fill:#fce4ec
```

### Key Components

#### ğŸ’¬ Chat Interface
- **Real-time Streaming**: Live response generation
- **Message Management**: Conversation history tracking
- **File Handling**: Data upload and download capabilities
- **Error Handling**: Graceful exception management

#### ğŸ› ï¸ Utility Functions
- **Session Management**: User-specific data isolation
- **File Operations**: Upload, download, and compression
- **Response Rendering**: Dynamic content display
- **Hash Generation**: Unique session identification

#### ğŸ“Š Graph Visualization
- **Interactive Diagrams**: Mermaid-based flowcharts
- **Pipeline Visualization**: ML workflow representation
- **Real-time Updates**: Dynamic graph rendering

---

## ğŸ¨ Template System

<div align="center">

> **ğŸ”§ Flexible Code and Content Generation Framework**

</div>

The template system enables dynamic content generation for AI prompts and executable code:

### Core Features

#### Template Processing
- **ğŸ”— Sub-template Resolution**: Nested template support
- **ğŸ“¦ Import Aggregation**: Automatic dependency management
- **ğŸ¨ Content Preservation**: Maintains code formatting and indentation

#### Placeholder Types

| Type | Syntax | Purpose |
|------|--------|---------|
| ğŸ”— **Sub-template** | `<%% template_name %%>` | Load and insert template files |
| ğŸ·ï¸ **Variable** | `{% var %}` | Direct variable substitution |

### Template Workflow

```mermaid
graph TD
    A[ğŸ“„ Template File] --> B[ğŸ” Load Template]
    B --> C{ğŸ”— Sub-templates?}
    C -->|Yes| D[ğŸ“š Load Sub-template]
    D --> E[ğŸ“¦ Extract Imports]
    E --> F[ğŸ”§ Process Content]
    F --> G[ğŸ“ Replace Placeholder]
    G --> C
    C -->|No| H[ğŸ¯ Aggregate Imports]
    H --> I[ğŸ“‹ Insert Imports]
    I --> J[âœ… Return Processed]
    
    style A fill:#e3f2fd
    style J fill:#4caf50
```

---

<div align="center">

## ğŸš€ Getting Started

Ready to dive in? Here's your next steps:

1. **ğŸ“¦ Install** FEDOT.LLM using our quick setup guide
2. **ğŸ”‘ Configure** your API keys for LLM access
3. **ğŸŒ Launch** the Streamlit interface
4. **ğŸ’¬ Start** your first AI conversation
5. **ğŸ¤– Explore** AutoML capabilities

### ğŸ¤ Contributing

We welcome contributions! Check out our:
- ğŸ“‹ [Issues](https://github.com/aimclub/FEDOT.LLM/issues)
- ğŸ”„ [Pull Requests](https://github.com/aimclub/FEDOT.LLM/pulls)
- ğŸ“– [Contributing Guidelines](https://github.com/aimclub/FEDOT.LLM/blob/main/CONTRIBUTING.md)

### ğŸ“ Support

Need help? Reach out through:
- ğŸ’¬ [GitHub Discussions](https://github.com/aimclub/FEDOT.LLM/discussions)
- ğŸ› [Issue Tracker](https://github.com/aimclub/FEDOT.LLM/issues)
- ğŸ“§ [Email Support](mailto:support@fedot-llm.ai)

---

<div align="center">

**Made with â¤ï¸ by the FEDOT.LLM Team**

[![GitHub stars](https://img.shields.io/github/stars/aimclub/FEDOT.LLM?style=social)](https://github.com/aimclub/FEDOT.LLM)
[![GitHub forks](https://img.shields.io/github/forks/aimclub/FEDOT.LLM?style=social)](https://github.com/aimclub/FEDOT.LLM)

</div>

</div>
